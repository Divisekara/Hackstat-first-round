{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ExitRates  TrafficType  Nov  A  K  X  Returning_Visitor  Revenue\n",
      "0       0.011111           10    0  0  1  1                  1        1\n",
      "1       0.022222            2    0  0  0  1                  1        0\n",
      "2       0.004444            2    0  0  1  1                  1        0\n",
      "3       0.002083            3    0  1  0  0                  0        1\n",
      "4       0.083333            1    0  1  1  1                  1        0\n",
      "5       0.034600            1    1  0  1  0                  1        1\n",
      "6       0.017358            3    0  0  1  0                  1        0\n",
      "7       0.014706            2    0  1  0  1                  1        1\n",
      "8       0.012500            2    0  0  1  1                  0        0\n",
      "9       0.017639            3    0  0  0  0                  1        0\n",
      "10      0.026099           20    1  0  1  0                  1        0\n",
      "11      0.032759           11    0  1  1  0                  1        0\n",
      "12      0.020000            3    0  0  0  1                  1        0\n",
      "13      0.020922            2    0  0  1  1                  1        0\n",
      "14      0.200000           20    0  0  0  0                  0        0\n",
      "15      0.046667           20    0  0  0  0                  1        0\n",
      "16      0.032381            2    0  0  0  1                  1        1\n",
      "17      0.009388            2    0  0  1  1                  1        0\n",
      "18      0.049312            1    0  0  1  1                  1        0\n",
      "19      0.002222           11    0  0  0  0                  0        0\n",
      "20      0.036975            3    0  0  0  1                  1        0\n",
      "21      0.006439            3    1  1  0  0                  1        0\n",
      "22      0.022222            2    1  1  0  0                  0        0\n",
      "23      0.025517            2    1  0  1  1                  1        0\n",
      "24      0.021429            1    0  0  0  1                  1        0\n",
      "25      0.066667            3    0  0  1  1                  1        0\n",
      "26      0.034332            2    0  1  1  1                  1        0\n",
      "27      0.005882            2    0  0  1  1                  0        0\n",
      "28      0.011111            2    1  0  1  1                  0        1\n",
      "29      0.126667            4    0  0  1  0                  1        0\n",
      "...          ...          ...  ... .. .. ..                ...      ...\n",
      "10450   0.026667            2    0  0  1  0                  1        0\n",
      "10451   0.014074            3    0  1  1  1                  1        0\n",
      "10452   0.014286            2    0  0  0  0                  0        0\n",
      "10453   0.006257            2    1  1  0  1                  1        0\n",
      "10454   0.010000            4    0  1  0  1                  1        0\n",
      "10455   0.175000           11    0  1  1  1                  1        0\n",
      "10456   0.020513           20    0  1  1  1                  1        0\n",
      "10457   0.025333            3    0  0  1  1                  1        0\n",
      "10458   0.200000            1    0  0  1  0                  1        0\n",
      "10459   0.031710           11    1  1  1  1                  1        0\n",
      "10460   0.022414            3    0  1  1  1                  1        0\n",
      "10461   0.028382            3    1  1  1  0                  1        0\n",
      "10462   0.023632            2    0  1  1  1                  1        0\n",
      "10463   0.056282            3    0  0  1  0                  1        0\n",
      "10464   0.001016            3    1  0  1  0                  0        0\n",
      "10465   0.033333            4    0  0  0  0                  1        1\n",
      "10466   0.080000            1    0  1  1  1                  1        0\n",
      "10467   0.026984            6    0  1  0  0                  1        0\n",
      "10468   0.025000            5    0  0  1  0                  1        0\n",
      "10469   0.200000            3    0  0  1  1                  1        0\n",
      "10470   0.030869            1    0  0  0  0                  1        0\n",
      "10471   0.020442            2    1  0  1  1                  1        1\n",
      "10472   0.042311            1    0  1  0  0                  1        0\n",
      "10473   0.011111            1    0  0  1  0                  1        0\n",
      "10474   0.052778           11    1  0  1  1                  1        0\n",
      "10475   0.083333            8    0  1  1  0                  1        0\n",
      "10476   0.016000            8    1  0  0  1                  0        1\n",
      "10477   0.017544            2    1  1  0  1                  1        1\n",
      "10478   0.019685           10    1  1  1  1                  1        0\n",
      "10479   0.003595            2    0  0  1  0                  0        0\n",
      "\n",
      "[10466 rows x 8 columns]\n",
      "Number of Training examples 10466\n",
      "Number of Testing examples 1850\n",
      "Index(['ExitRates', 'TrafficType', 'Nov', 'A', 'K', 'X', 'Returning_Visitor'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    3 ... 1848 1849 1850]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math as ma\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
    " #   for filename in filenames:\n",
    " #       print(os.path.join(dirname, filename))\n",
    "\n",
    "#Trainset = pd.read_csv(\"/kaggle/input/hackstat2k19/Trainset.csv\", header = 0) \n",
    "Trainset = pd.read_csv(\"E:\\\\jup4\\\\Trainset.csv\", header = 0)\n",
    "Trainset = Trainset.dropna()\n",
    "\n",
    "sampleset = pd.read_csv(\"E:\\\\jup4\\\\sample_submisison.csv\", header = 0) \n",
    "sampleset = sampleset.dropna()\n",
    "\n",
    "#Trainset  = Trainset.replace(to_replace=['Jan', 'Feb','Mar','Apr','May','June','Jul','Aug','Sep','Oct','Nov','Dec'], value=[0,2,166,0,307,21,54,69,72,97,641,183])\n",
    "#Trainset  = Trainset.replace(to_replace=['Returning_Visitor', 'New_Visitor' , 'Other'], value=[1242, 366, 11])\n",
    "\n",
    "xset = pd.read_csv(\"E:\\\\jup4\\\\xtest.csv\")\n",
    "xset = xset.dropna()\n",
    "\n",
    "#xset  = xset.replace(to_replace=['Jan', 'Feb','Mar','Apr','May','June','Jul','Aug','Sep','Oct','Nov','Dec'], value=[0,2,166,0,307,21,54,69,72,97,641,183])\n",
    "#xset  = xset.replace(to_replace=['Returning_Visitor', 'New_Visitor' , 'Other'], value=[1242, 366, 11])\n",
    "\n",
    "#Trainset['is_train'] = np.random.uniform(0,1,len(Trainset)) <= 0.75\n",
    "print(Trainset)\n",
    "\n",
    "Train, Test = Trainset,xset\n",
    "\n",
    "print('Number of Training examples', len(Train))\n",
    "print('Number of Testing examples', len(Test))\n",
    "#############################################################################################################3\n",
    "features = Trainset.columns[:7]\n",
    "print(features)\n",
    "y = Train['Revenue']\n",
    "y\n",
    "\n",
    "id_ = sampleset['ID']\n",
    "#new_ = id_.DataFarame(id_)\n",
    "clf = RandomForestClassifier(n_jobs = 2, random_state = 0)\n",
    "clf.fit(Train[features],y)\n",
    "\n",
    "clf.predict(Test[features])\n",
    "\n",
    "#clf.predict_proba(Test[features])\n",
    "\n",
    "preds = clf.predict(Test[features])\n",
    "\n",
    "#print(tpe(new_))\n",
    "#print(type(preds))\n",
    "YArray= id_.as_matrix(columns=None)\n",
    "print (YArray)\n",
    "\n",
    "df = pd.DataFrame({\"ID\" : YArray, \"Revenue\" : preds})\n",
    "df.to_csv(\"E:\\\\jup4\\\\submission.csv\", index=False)\n",
    "#dfObj = pd.DataFrame(YArray,preds,columns = [\"ID\",\"Revenue\"]) \n",
    "\n",
    "#dfObj.to_csv('submit.csv', index = False)\n",
    "\n",
    "#pd.crosstab(Test['Revenue'], preds, rownames = ['Actual Revenue'], colnames = ['Predicted Revenue'])\n",
    "#Test['Revenue']\n",
    "#X, y = Trainset.iloc[:, :16], Trainset.iloc[:, 17]\n",
    "\n",
    "#Xset = xset.iloc[:, :16]\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=10)\n",
    "#clf = clf.fit(X, y)\n",
    "#clf\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=17, max_depth=None,min_samples_split=2, random_state=0)\n",
    "#scores = cross_val_score(clf, X, y, cv=5)\n",
    "#scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Contactus_Duration'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-a9e6af58e22c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mTrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mTrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Contactus_Duration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'columns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Revenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Contactus_Duration'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "#import math as ma\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input/'):\n",
    " #   for filename in filenames:\n",
    "  #      print(os.path.join(dirname, filename))\n",
    "\n",
    "#Trainset = pd.read_csv(\"E:\\\\jup3\\\\Trainset.csv\", header = 0) \n",
    "#Trainset = Trainset.dropna()\n",
    "\n",
    "sampleset = pd.read_csv(\"E:\\\\jup3\\\\sample_submisison.csv\", header = 0) \n",
    "sampleset = sampleset.dropna()\n",
    "\n",
    "Trainset = pd.read_csv(\"E:\\\\jup3\\\\Trainset.csv\", header = 0) \n",
    "Trainset = Trainset.dropna()\n",
    "\n",
    "Trainset = Trainset.drop(['Contactus_Duration'], axis = 'columns')\n",
    "\n",
    "y = Trainset['Revenue']\n",
    "xset = pd.read_csv(\"E:\\\\jup3\\\\xtest.csv\")\n",
    "xset = xset.dropna()\n",
    "\n",
    "xset = xset.drop(['Contactus_Duration'], axis = 'columns')\n",
    "\n",
    "print(Trainset)\n",
    "\n",
    "Train, Test = Trainset,xset\n",
    "\n",
    "print('Number of Training examples', len(Train))\n",
    "print('Number of Testing examples', len(Test))\n",
    "\n",
    "features = Test.columns[1:52]\n",
    "print(features)\n",
    "y\n",
    "\n",
    "id_ = sampleset['ID']\n",
    "#new_ = id_.DataFarame(id_)\n",
    "clf = RandomForestClassifier(n_jobs = 2, random_state = 0)\n",
    "clf.fit(Train[features],y)\n",
    "\n",
    "clf.predict(Test[features])\n",
    "\n",
    "clf.predict_proba(Test[features])\n",
    "\n",
    "preds = clf.predict(Test[features])\n",
    "\n",
    "print(\"Random forest = \", preds)\n",
    "#print(tpe(new_))\n",
    "#print(type(preds))\n",
    "YArray= id_.as_matrix(columns=None)\n",
    "#print (YArray)\n",
    "\n",
    "df = pd.DataFrame({\"ID\" : YArray, \"Revenue\" : preds})\n",
    "df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "#########################################################################################################\n",
    "#from sklearn import datasets\n",
    "#iris = datasets.load_iris()\n",
    "#nb = MultinomialNB()\n",
    "#nbclassifier = nb.fit(Train[features], y)\n",
    "#y_pred_nb = nbclassifier.predict(Test[features])\n",
    "#>>> print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "#...       % (iris.data.shape[0],(iris.target != y_pred).sum()))\n",
    "#Number of mislabeled points out of a total 150 points : 6\n",
    "#print(\"Gaussian Naive Bayes = \", y_pred_gnb)\n",
    "#########################################################################################################\n",
    "\n",
    "#ncclf = NearestCentroid()\n",
    "#ncclf.fit(Train[features], y)\n",
    "#y_pred_nc = ncclf.predict(Test[features])\n",
    "#print(\"nb = \", y_pred_nb)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdclf = SGDClassifier()\n",
    "sgdclf.fit(Train[features], y) \n",
    "y_pred_sgd = sgdclf.predict(Test[features])  \n",
    "print(\"sgd = \", y_pred_sgd)\n",
    "#########################################################################################################\n",
    "\n",
    "from sklearn import tree\n",
    "#iris = load_iris()\n",
    "treeclf = tree.DecisionTreeClassifier()\n",
    "treeclf = treeclf.fit(Train[features], y)\n",
    "y_pred_tree = treeclf.predict(Test[features])\n",
    "print(\"Decision Tree classifier = \",y_pred_tree)\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "svmclf = svm.SVC(gamma='scale')\n",
    "svmclf.fit(Train[features], y)  \n",
    "y_pred_svm = svmclf.predict(Test[features])\n",
    "print(\"svm classifier = \",y_pred_svm)\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "knnclassifier = KNeighborsClassifier()\n",
    "knnclassifier.fit(Train[features], y) \n",
    "y_pred_knn = knnclassifier.predict(Test[features])\n",
    "print(\"KNN classifier = \",y_pred_knn)\n",
    "\n",
    "#########################################################################################################\n",
    "df = pd.DataFrame({\"ID\" : YArray, \"Random\" : preds, \"sgd\" : y_pred_sgd,\"tree\" : y_pred_tree, \"svm\" : y_pred_svm, \"knn\" : y_pred_knn})\n",
    "df.to_csv(\"E:\\\\jup3\\\\submission1.csv\", index=False)\n",
    "df\n",
    "#svclassifier = SVC(kernel='linear')\n",
    "#svclassifier.fit(Train[features], y)\n",
    "#y_pred = svclassifier.predict(Test)\n",
    "#print(\"SVC classifier = \",y_pred)\n",
    "count = 0\n",
    "pred_list = []\n",
    "for i in range(len(y_pred_knn)):\n",
    "    count = 0\n",
    "    c_list = [preds[i],y_pred_sgd[i],y_pred_tree[i],y_pred_svm[i],y_pred_knn[i]]\n",
    "    for j in range(5):\n",
    "        if c_list[j] == 1:\n",
    "            count += 1\n",
    "    if count >= 2:\n",
    "        pred_list += [1]\n",
    "    else:\n",
    "        pred_list += [0]\n",
    "print(len(pred_list))\n",
    "o = pd.DataFrame(pred_list) \n",
    "\n",
    "pred_= o.as_matrix(columns=None)\n",
    "df = pd.DataFrame({\"ID\" : YArray, \"Revenue\" : pred_list})\n",
    "df.to_csv(\"E:\\\\jup3\\\\submission_new3.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
